{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agentes en LangGraph con Gemini\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Caso 6 Agente con memoria\n",
        "\n",
        "<img src=\"https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbab7453080e6802cd1703_agent-memory1.png\" alt=\"gate\" width=\"600\"/>\n",
        "\n",
        "Muchos de las aplicaciones de agentes requieren tener memoria para que el agente pueda validar eventos, contexto o datos anteriormente suministrados en la conversaci칩n. Existen dos tipos de memoria: a corto plazo y largo plano.\n",
        "\n",
        "### Memoria a corto plazo: \n",
        "usualmente se habla de un id de conversaci칩n. Si ha interactuado con uno o varios agente en una intenci칩n de forma reciente, es lo que se considera memoria a corto plazo\n",
        "\n",
        "### Memoria a largo plazo: \n",
        "usualmente asociado al id del usurio, esta memoria es el historico de conversaciones o eventos que han pasado en multiples interacciones en una ventana de tiempo extenza por uno o varios agente de IA o humanos incluso cuando la memoria se mezcla con eventos en un CRM para canales de atenci칩n\n",
        "\n",
        "En este ejemplo trabajaremos la memoria a corto plazo. Hay diferentes herramientas o formas de tener memoria a largo plazo, recomiendo usar herramientas como [Memory Bank](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/overview) de GCP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langgraph.graph import MessagesState\n",
        "from langgraph.prebuilt import tools_condition, ToolNode\n",
        "#from typing_extensions import Literal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Declaraci칩n y llamado de la key del modelo LLM\n",
        "# use esta funci칩n para definir la key del modelo LLM si tuvo problemas con el archivo .env.json o create_env.py\n",
        "def _set_env(var: str):\n",
        "   if not os.environ.get(var):\n",
        "       os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"GOOGLE_API_KEY\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Iniciamos definiendo algunas tools para nuestro agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"\n",
        "    Multiplica dos n칰meros enteros y retorna el resultado.\n",
        "\n",
        "    Esta funci칩n toma dos argumentos de tipo entero, 'a' y 'b', y retorna el producto de ambos.\n",
        "    Es 칰til cuando se requiere realizar operaciones de multiplicaci칩n en flujos de trabajo matem치ticos\n",
        "    o como parte de herramientas de c치lculo para agentes conversacionales.\n",
        "\n",
        "    Args:\n",
        "        a: Primer n칰mero entero a multiplicar.\n",
        "        b: Segundo n칰mero entero a multiplicar.\n",
        "\n",
        "    Returns:\n",
        "        El resultado de multiplicar 'a' por 'b' como un entero.\n",
        "    \"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"\n",
        "    Suma dos n칰meros enteros y retorna el resultado.\n",
        "\n",
        "    Esta funci칩n recibe dos argumentos de tipo entero, 'a' y 'b', y retorna la suma de ambos.\n",
        "    Es 칰til para realizar operaciones aritm칠ticas b치sicas, como sumar cantidades, totales o valores\n",
        "    en diferentes contextos dentro de un agente conversacional.\n",
        "\n",
        "    Args:\n",
        "        a: Primer n칰mero entero a sumar.\n",
        "        b: Segundo n칰mero entero a sumar.\n",
        "\n",
        "    Returns:\n",
        "        La suma de 'a' y 'b' como un entero.\n",
        "    \"\"\"\n",
        "    return a + b\n",
        "\n",
        "def divide(a: int, b: int) -> float:\n",
        "    \"\"\"\n",
        "    Divide el primer n칰mero entero por el segundo y retorna el resultado como flotante.\n",
        "\n",
        "    Esta funci칩n toma dos argumentos de tipo entero, 'a' y 'b', y retorna el cociente de la divisi칩n de 'a' entre 'b'.\n",
        "    Es importante asegurarse de que 'b' no sea cero para evitar errores de divisi칩n.\n",
        "    Es 칰til para calcular proporciones, promedios u otras operaciones que requieran divisi칩n en agentes conversacionales.\n",
        "\n",
        "    Args:\n",
        "        a: N칰mero entero que ser치 el dividendo.\n",
        "        b: N칰mero entero que ser치 el divisor (no debe ser cero).\n",
        "\n",
        "    Returns:\n",
        "        El resultado de dividir 'a' entre 'b' como un n칰mero flotante.\n",
        "    \"\"\"\n",
        "    return a / b\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definimos estas funciones como tools para nuestro agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "tools = [add, multiply, divide]\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora definimos la entrada del mensaje que nos dar치 el usurio y el nodo que usaremos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Esta l칤nea crea un mensaje de sistema (SystemMessage) que se utiliza para establecer el comportamiento y las instrucciones iniciales del asistente conversacional.\n",
        "# El contenido del mensaje indica que el asistente debe ser 칰til y est치 encargado de realizar operaciones aritm칠ticas sobre un conjunto de entradas.\n",
        "# Este mensaje se env칤a al modelo de lenguaje como contexto para guiar sus respuestas y asegurar que act칰e de acuerdo a la tarea especificada.\n",
        "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
        "\n",
        "# Nodo\n",
        "def assistant(state: MessagesState):\n",
        "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Inicializamos el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = StateGraph(MessagesState)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora agregamos los nodos, que ser치n `assistant` y las Tools que definimos incialmente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x2863c9fbec0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "builder.add_node(\"assistant\", assistant)\n",
        "builder.add_node(\"tools\", ToolNode(tools))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora definimos las aristas de nuestro grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "builder.add_edge(START, \"assistant\")\n",
        "builder.add_conditional_edges(\n",
        "    \"assistant\",\n",
        "    # Si el 칰ltimo mensaje (resultado) del asistente es una llamada a una herramienta -> tools_condition dirige a tools\n",
        "    # Si el 칰ltimo mensaje (resultado) del asistente NO es una llamada a una herramienta -> tools_condition dirige a END\n",
        "    tools_condition,\n",
        ")\n",
        "builder.add_edge(\"tools\", \"assistant\")\n",
        "react_graph = builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compilamos el grafo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "react_graph = builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora podemos visualizar el grafo que hemos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAAAXNSR0IArs4c6QAAIABJREFUeJzt3XdcU1f/B/BzswcJkIRpQEAFZCgoSktdFSviqGLdWtfP3UWrtbXWqt3DPlqt1WK1VrSOinvUotYFooKCAiogStkQRhKy1++P+FAeDBE0N/eEe94v/8B7wz1f8OO5565zMZPJBBCEaBSiC0AQgIKIwAIFEYECCiICBRREBAooiAgUaEQXAB2t2iAp1yrlBqVcb9CbdFoHOL3FZFNoDIzDo3F4FA9fNtHlPAsMnUc0UzbpC7OainMV9VUaF3cGh0fl8Gh8AU2ncYDfD51FaajSKuV6GgMruasMCHMK6MXt1suJ6Lo6AAURmEym9ON1VY9Ubj6sgDCuuAeH6Iqei1ZtLM5tKr2vKi9SxYwRBvbhEV1Ru5A9iHevyc7tq4kZI+wz1JXoWmxM3qBLP16nlOuHv+7J5cM+BiN1EC8dqqXSwUtj3IguBEf11ZojmyuGTfPwDYa6pydvEP/+o0bgweg9yIXoQuzh6NbyF0YKPXxZRBfSJpIG8XhShU8QJ2IwKVJodnRLeXA/flAUpENGMp5HTD8u8e7GJlUKAQBjF3e5eb5BUqEhuhDLSBfEwltyAEDf2M52aNIeU5f7XjpUazLCuA8kXRAvptRGvkzGFJoFhDtdOSohugoLyBXEWxcagqP4bCcq0YUQJmKwS+GtJoVMT3QhrZEriI/yFC+OERBdBcEGjRdlX2wkuorWSBTER/kKGp1CpZLoR7bIN5ibmyYluorWSPSv8vCOwj+ca+dGP/zww6NHjz7DN77yyivl5eU4VAQYLIqbmFlepMJj48+MREGsr9F2s3sQ8/Pzn+G7KisrGxoacCjnscBIp7IiJX7bfwZkCaJWbZSUa9hOeF1yTUtLW7hw4YABA8aNG7d69WqJRAIAiIqKqqio+Oyzz4YMGQIAaGpq2rp166xZs8wfW79+vVqtNn97bGzs3r1758+fHxUVdfHixTFjxgAAxo4du3TpUjyq5TrTa8sgO6FoIof6ak3yF49w2vjdu3f79u27bdu2ysrKtLS0KVOmvPHGGyaTSa1W9+3b98iRI+aPbdu2LTo6OjU19caNG+fPn4+Pj//hhx/Mq+Li4iZOnPjdd99lZGTodLrLly/37du3rKwMp4KrS1T7vv8Hp40/G9hvyrAVhVTPdcbrh83OzmaxWHPnzqVQKJ6eniEhIUVFRU9+bMaMGbGxsf7+/ua/5uTkpKenv/322wAADMOcnZ2XLVuGU4WtcJ1pCilcZ3DIEkSjETDYeI1DIiIi1Gp1YmJidHT0oEGDfHx8oqKinvwYnU6/evXq6tWrCwoK9Ho9AEAg+PdcUkhICE7lPYlCwxgsuEZlcFWDHy6fKq3V4bTx4ODgjRs3urm5bdq0KSEhYcmSJTk5OU9+bNOmTUlJSQkJCUeOHMnMzJwzZ07LtQwGA6fynqRo1FNpmN2aaw+yBJHDpynxvJwQExOzatWq48ePr1mzRiqVJiYmmvu8ZiaTKSUlZfLkyQkJCZ6engAAuVyOXz3WKWR62G6VJUsQ2VyqqAtTrzPisfGsrKz09HQAgJub2+jRo5cuXSqXyysrK1t+RqfTqVQqd3d381+1Wu2lS5fwKKY9NEqjuw+TqNYtIksQAQBsJ2rxHQUeW87JyVm+fPmhQ4caGhpyc3P37dvn5ubm5eXFZDLd3d0zMjIyMzMpFIqfn9+xY8fKysoaGxs//fTTiIgImUymUFgoyc/PDwCQmpqam5uLR8EFN+UeXeG6SZZEQfQP4z7MxSWIM2bMSEhIWLdu3SuvvLJgwQIul5uUlESj0QAAc+fOvXHjxtKlS1Uq1ZdffslisSZMmDBu3Lj+/fu/+eabLBZr2LBhFRUVrTYoFovHjBmzdevWTZs24VHwo3ylf6i9z+1bR6I7tLUa48ntlQlLuhBdCMH+ua8svtM0ZII70YX8DxL1iAwmxV3MvHkex0tnDiH9mCT0RWeiq2gNrkMnvMWMFm5e9qCtJ0eNRuPQoUMtrtJqtXQ6HcMsnPIICAjYsWOHrSt9LDs7OzExsaMlBQYGJiUlWfyugptyVw+GWxe4jlTItWs2y7nUaDSaIodYzmJbp1Q0Gg2TafkfD8MwJycc51R4hpIoFAqXa3kIeHJ7xcAEN76AbtMabYB0QQQAnNpRGRTFc6wZOWwC5h+cRGPEZiPnel09UVdTqia6ELu6mFIr9GLAmUKS9oiPr3P8UPbCKKGjz3TTThdTat19mT378YkupE1k7BHNA7sJiT43/mrIy4DupnnbMplMR7eU8wU0mFNI3h6x2dWTkod5ypjRQr8QuE7w2kRman1ehuzlSe6+QbB3/GQPIgCgrkKTfqKOyaZ06cH2D+VyeA5/Squ2TFNyV5F1rqHXQJfoeAGFAteNNhahID5W/kB1/4b8YZ7C1YMu8GBwnWlcPo3rTDUYiK6sHTDMJK/XK2QGk9FUcLOJxaV07+3Ua6ALbDcdWoGC2FrVI1VtuVYh1StkegoFU8ptmUSVSlVcXBwaGmrDbQIAnFxpwAS4fCrPlebdjc1zhe404VOhINrVgwcPVqxYceDAAaILgY7DdN1I54aCiEABBRGBAgoiAgUURAQKKIgIFFAQESigICJQQEFEoICCiEABBRGBAgoiAgUURAQKKIgIFFAQESigICJQQEFEoICCiEABBRGBAgoiAgUURAQKKIgIFFAQESigINoVhmHNb7hAWkJBtCuTyVRTU0N0FTBCQUSggIKIQAEFEYECCiICBRREBAooiAgUUBARKKAgIlBAQUSggIKIQAEFEYECCiICBRREBAooiAgUUBARKKAX/tjDlClTlEolAECr1dbV1Xl5eZlfQX/mzBmiS4MF6hHtYezYsVVVVRUVFRKJxGQyVVRUVFRU8Hg8ouuCCAqiPUyZMsXX17flEgzDBgwYQFxF0EFBtAcMw8aPH0+lUpuXdO3adfLkyYQWBRcURDuZNGmSj4+P+WsMwwYPHmweKSJmKIh2QqPRpkyZwmQyAQBisXjChAlEVwQXFET7GT9+vFgsBgDExMSg7rAVGtEF2JuqyVBXodVqjYS0PiZ2XqoxdUj/ycW5CiLaNzm50AQeDBodug6IROcR9VrjX7uryx+oxIFcnZqYIBKLzqA01moNemNgX17/OAHR5fwPsgRRozKkbCzvFy/y7MohuhbiZf4lodLAoAQR0YX8C7ouGif715UOmeSFUmgWNVxkMmHpJ+qILuRfpAhibro0oDePJ6ATXQhE+sQKK4pVTTI90YU8RoogVpWoOXyUwtYwDGuo0hJdxWOkCKJWbeQLURBbE3gxFY0Goqt4jBRBVCuMJjIeJT+FVm00GGE5VCVFEBH4oSAiUEBBRKCAgohAAQURgQIKIgIFFEQECiiICBRQEBEooCAiUEBBRKCAgoiv4uKil2Ojbt++RXQhsENBxJeLi+vM1+e5u3ta+czDhw+mTBv9nA0lvPZKRWX5c26EQKR7eMrOBALhnNmLrH/mfkH+c7ZSVVXZ2NjwnBshFgqiZVevXj7/95nbd27JZNKewWGvvz4vMiLKvCrjWtr+/bvu3c8TCERhYb0XzHtLKBS1tby4uOj/5k/5Yf22Xr0i5U3yX3duvZZxpaGxPigwZNiw+FEjx/26c+uu5F8AAC/HRi1Z/O7ECdPbavrwkQPJu3/Z8J+k1WuXP3pUHBDQfeKE6SPixtzKznxv6SIAwPQZY6dNnT1/3ptE//KeBdo1W6BWq7/46mONRvPhB2u//GKDr6/fyo/fra+vAwAUFN5b8dE7kZH9du44+PZbyx88KPjm2zVWlrf07bdr8/NuJyau2LnjYM+eYes3fJWXd3vO7EVTJs/08PD8+1zmxAnTrTRNp9ObmuQbN337/tJV58/eGDxo2LfffVpdXRUZEfXVFxsAAHt2H3XQFKIe0TIWi/VL0j42m+3s7AIA6BkcdvTYwTu52YMHxebeyWaxWDOmz6VQKB4ensFBIcUPiwAAbS1vKef2zSmTZ/aLegEAsGD+W4MHD3Pmu7S/aQCATqebNXNBSEg4ACBu+Ohfd24tKrrv4WFtAOooUBAtUyoVv2z/MTsnq65OYl5iHoSFhUeo1eoVKxOj+ka/+OIgcRcf836zreUthYdHHPhjt1Ta2LtXn379XgwK7Nmhps2Cg0PNX/B4fABAU5Mcn1+AvaFdswXV1VXvvDtPp9OtWvnlX39eTT2T0bwqsEfw119tFAndkrZten1mwrL3l+Tm5lhZ3tIHy9dMeG3ajcyrK1e9N/61V3b8ukWvb/0QnZWmzTAMw+3nJhLqES24cDFVq9V++MFaNpvdqkMCAET3j4nuHzNn9qKsrGsph/Z+tDLxUEoqjUazuLzlN/J5/BnT506fNic3N+fylb+Td293cuJNmjij/U13YiiIFshkUh6Pb44CAODipXPNq7KzszRaTXT/GJHILS5utKend+J7C6qqKyW1NRaXN3+jVCY9d+7PkfFjWSxWeHhEeHhEUdH9gsJ77W+6c0O7ZgsCAnrU1UmOHU/R6/XXrqffvHnd2dmlpqYKAJCbl7Nm7fLjJw41Njbk3809dHifSOTm6eHV1vLmbdKotN92Ja359IPc3Jz6+rq//jpZWHQvPCwCACAW+9bVSa5cuVBaWmKlaSt8fP0AABcupJaUPMT/14ML6po1rc8ydD53r8s9urKdXNr7aHOAf3ej0XAw5fefkzZKpQ1L31upUin3H0iur5fMmb1ILpft3rP99707z549FRjY8/33P3FxcQ0ODrW4vKGh/tjxg/EjXvXx8Q3pGX7hYuqe33898Mfu8orSma/PHzVyHIZhQoHo/v383/ft5PNdxidMbqtpodDt6tXLM1+fR6FQzEfQv+/9dcBLQ7p3D+Tz+NXVlYcO7wMYFt0/pp0/ZmmBgi+guYuZz/GrtRlSTMJ06Mfy8IECTz820YXAJf14jbg7K/QFPtGFALRrRmCBgohAAQURgQIKIgIFFEQECiiICBRQEBEooCAiUEBBRKCAgohAAQURgQIKIgIFFEQECqQIorOIBkhwk1FHMVkUBhOWBw9IEUQ2l1pbriG6CuiUFykFHgyiq3iMFEHsGsptrIXlFUuQUCsNbCeq0BuKu2LJEsQuAWyBOy3jRA3RhUDk7O6KAeMgejspKe7QNss821BTqvHuxhF1YVFppPgf2AqGmeSNerlEe+20ZMoyH1do9svkCiIA4NFdRUFWk0phaGzxMkSNVkuhUOg0ezzQaDSZdDodk4FXAhRKJYZhVCqV8l8tD0YYHCqDiXkFsPoPF9AYcP1XJFcQWzEYDEVFRRcuXFi4cKF9Wnzw4MGKFSsOHDiA0/ZXrFhx5swZDMNcXV2dnJyYTKa3t3dgYODixYtxatFWyBvEXbt2jRo1isvlslgsuzUql8uzsrKGDBmC0/bv3buXmJgokUhaLjQajV5eXidPnsSpUZuAq3+2m5SUlIaGBqFQaM8UAgB4PB5+KQQABAcH9+zZekodLpcLeQrJGMTz588DAF566aV33nnH/q3X1tb+9NNPuDYxbdo0V1fX5r9SKJTLly/j2qJNkCuIX3/9dXFxMQDA05OYqdxkMtmFCxdwbaJfv37dunUzj7iMRmNAQMDRo0dxbdEmSDHTAwCgqKhIIBBwudxRo0YRWAadTheLxX5+fri2wuFwrl+/rtFoxGJxSkrKgQMH0tLSBg4ciGujz4kUBysrVqyIjY0dNmwY0YXYz/Tp06urq8+ePWv+a0pKyuHDh3fv3k10XW0zdWpyuby0tPTMmTNEF/JYTU3N5s2bCWk6Pz+/b9++ubm5hLT+VJ15jPjZZ59JJBKxWDx8+HCia3nMDmPEtvTs2TMzM/Obb745ePAgIQVY12mDmJKSEh4ejvdorKPc3d2XLFlCYAG7du0qLCxcu3YtgTVY1AnHiElJSQsWLNBqtQzcrqQ5umPHju3Zsyc5ORmeX1Fn6xE/+eQTFxcXAAA8v+KW7HAesT1effXVL774YvDgwdnZ2UTX8l9ED1Jt5sKFCyaTqba2luhCrCkqKpo4cSLRVfxr7ty5e/bsIboKU+c5WJk+fbp5un2RCKJ77J5E+Bixle3bt1dWVn788cdEF+L4Y8SysjJ3d/fi4uLg4GCia3FUp0+f3rZtW3JyMpfLJaoGB+4R9Xr9/Pnz1Wo1g8FwlBRCMkZsJT4+fv369fHx8Tdu3CCqBkcNoslkSktLW7x4cffu3YmupQMIPI9oXdeuXS9durR9+/bffvuNkAIcL4hGo/Hdd981mUyDBw/u06cP0eV0DGxjxFa2bt0qlUqXL19u/6Ydb4y4evXq2NjYQYMGEV1Ip3Xu3LkNGzYkJyebT4TZCdGH7R2wc+dOokt4XgRea+6Q8vLyoUOHXrlyxW4tOsyuecSIEWFhYURX8bygHSO24u3tfe7cuf379//yyy/2adEBds03b97s06ePWq228239eMD7mRWb27JlS0FBwfr16/FuCOoeUaFQxMXF8fl88xu1iS7HBvB+ZsXmFi9enJCQEBcXV1OD8/QEdhsEdJRcLi8oKID8kl1HOcoYsZXa2toRI0ZkZ2fj1wSkPeKhQ4du3rzZo0cPyC/ZdRSLxbp16xbRVXSYSCQ6ffr05s2by8vLcWoC0vc1FxYW6nQ6oquwPR6P99NPP6lUKgzDHG6wcfPmTW9vb5w2DmmPuGjRotGjRxNdBS7odDqbzd6/f39lZWU7Pg6Le/fuBQUFme8swQOkQXR2dibwArwdzJo1KzExkegqOuDu3btPPrpvQ5AG8eeffz5x4gTRVeBr//79AIDS0lKiC2mX/Pz8kJAQ/LYPaRClUqlCoSC6Cnu4ePFiVlYW0VU8Hd49IqQntKVSKY1G69x752aff/45DLemWhcVFZWZmYnf9iHtETv9GLElcwozMjKILqRN+fn5uHaH8AaRDGPEVsrKys6cOUN0FZbhvV+GN4jkGSM2mzBhgkwmI7oKy/A+UoE3iAsXLuys5xGtmDhxIgBg7969RBfSGnl7RFKNEVsRCoVQzQpiNBoLCwuDgoJwbQXSIJJwjNhs+PDhUM2UYof9MrxBJOEYsaWoqCjzrBVEFwLss1+GN4jkHCO2kpCQsGfPHqKrsFMQIb37xtnZmegSiBcZGenh4UF0FSA/P3/q1Kl4twJpj0jmMWJL5tuuEhISiCpAr9c/fPiwR48eeDcEaRBJPkZsZevWrcnJyS2X2G3qUfscqaBrzQ5Dq9VqtVoqlcpms0eOHFldXR0XF/fll1/i3e7+/ftLSkrs8Mg9GiM6BgaDwWAwBgwY4OLiUlNTg2FYXl5efX29QCDAtd38/Px+/frh2oQZpLtmNEa0SCgUVlVVmb+ur6+3w5t87HPIDG8Q0RjxSa+99lrLZ5cUCkVqaiquLWq12tLS0m7duuHaihmku+aFCxfS7PLeWkeRkJBQUlJifqWZeQmFQikpKSkuLg4ICMCpUbsdqcDbI5L5WrNFhw8fTkhI8PPzM0+MZDQaAQDV1dW47p3ttl+Gt0f8+eefu3Tpgi6utLRq1SoAwO3bty9fvnz58uW6ujppg/LiuevjX52OU4v38/6JjIyUN+ifeQsmE+AL2pUxuE7fDB06VCqVNpeEYZjJZPL09Dx16hTRpcElM7X+9pUGI6bXa0xs3J6P1uv1VBrteR4gdfVilhcqu/fmRo8U8gV0K5+Eq0eMiYk5depU8zDIPBIaM2YMoUVB58/fqpwE9Pi5vk4u1v5pIaHXGRtrtH/8UDb+jS6u7m2+cwSuMeLUqVNbzSUgFovtcKHTgZzeWeXqyew9SOgQKQQA0OgUURfWpPf8D28ul9W3OXsHXEEMDQ1tOQkihmEjRoyw67ylcHuUr2CwqSEvuLbjs9B5ebJXxqn6ttbCFUQAwMyZM5snXhKLxZMmTSK6IojUlGroTOj+ydrJ1YNZlC1vay10P1VISEivXr3MX8fHx7u6OuT/fpxolAaRF5PoKp4RlYb5BnEba7UW10IXRADA7NmzhUKhp6cn6g5bUcgMekeeI62+WtvWNE7Pe9Rc8UAplegVcr1SZjAagF5vfM4NAgAAEA4IWszlcjNPawCofv7NMdkUDGAcPpXDpwq9mW7ejtqpdGLPGMSSu4qCm03FuQpXT7bJhFHpVAqdSqFSbXVWMqzXEACA3EZXm5uUmNFgMJTrDVq1Ti3VqQ3denGDo3geXR1shsJOrMNBrHyounS4js5hYDRmtxddaXQqPoXhSKvS10kUF480sDlg4DihixuML9Qlm44F8eze2opitdBfwHV14L6EwaYJfJwBALIaRcqmip79eTGjhUQXRXbtPVjR64w7Py1RG5i+fbwdOoUt8d253V70qamiHN6M19TQSDu1K4gGvSlpRbFXiIeTsBPeEePShU935u9b5xgTZnZWTw+i0WjasvxBSKw/k+sY15SegZOQw+8i+O3zEqILIa+nB3HPV//0iOlil2KIxHFhCXxcTm53pAnWO5OnBPFCisTFx4XJJcVxJc/dSQeY2RcbiS6EjKwFsa5C8zBXwXNzsmM9BHPxdr5yRALVPZokYS2Il47UifzxfVoRQp6BrpeP1BFdBem0GcSqRyq9gcJz49i3nvbKvnN22aroJkWDzbcs8nMpL9ZoVAabb9lBjRs/bFcy7i/LbTOIRTkKjNppD5OfAqM8ylMSXYRtrP30w1OnjxJdxdO1GcQHtxU8d0i7Q7xxBNzC7Caiq7CN+/fziS6hXSxf4muo0bJ5dPwOlh/9c/uvv38pLct34rr2DBow/OV5LBYXAJCW8UfqxR2L527ZtW9FdU2xl0f3QTFT+/V5/CzfiT83ZeacYjI4kb3i3EW+ONUGAOC7cyrzIJ1XvUNejo0CAHy37rMtW9cfP3oBAJCWdvG3XUkl/zx0dnbp3j3onbc+8PDwNH/YyqpmGdfS9u/fde9+nkAgCgvrvWDeW0KhbV4fa7lHbGrUq1U2uaHLAkld6c8739LpNG8u+GXWtG8qqwu37FhsMOgBAFQaXaWSHzm5btK4j777NKNX2NADRz5vaKwCAKRfT0m/fnD8qPffWfir0NU79e/tOJVnfkShqUGnkD37Y5SQ+PNUGgDg/WWrzCnMzLr2yZr3hw8fdWDfqdWrvq6urtyw8WvzJ62salZQeG/FR+9ERvbbuePg228tf/Cg4Jtv19iqVMtBVMoMVNxuq7mZ8yeNSp899RsPNz9P94CJY1eWV97PvXvRvNZg0L3y8ryuPuEYhkVFjDKZTOWVBQCAK1cP9AqN7RU2lMPh9+szuntAFE7lmTFYVIXU4YPYyo5ftwwaOHTCa9OcnV1CQ3stWfxeRsaVe/fzra9qlnsnm8VizZg+18PDM7p/zPffbZk6dbatamsjiHI9lYHXk6aP/rntIw7hch8/EiVw9RIKxA9Lsps/4Nsl1PwFh80HAKjUcpPJJKkv9XD3b/6M2DsYp/LM6Gyq0vF7xFaKiwuDg0Ob/xoUGAIAuHcvz/qqZmHhEWq1esXKxD8O7ikrL3V2domMsFl30GbaMIDXSV2Vuqm0PH/ZquiWC2Xyf0/dPXk3uVqjMBoNTOa/B08MBhun8syMBgBwezcxIZqamjQaDZP5751THA4HAKBUKqysarmFwB7BX3+18dKlc0nbNv20ZX3fPv1nz1oYFtbbJuVZDiKHTzPo1DZp4Ek8ntC/a0Tc0AUtF3K51iZEZDG5FApV16IkjRbf0ysGrYHLh2v2gefEYrEAAGq1qnmJQqkAAAgFIiurWm0kun9MdP+YObMXZWVdSzm096OViYcPnaVSbTCKs7xr5vCoBh1eZ3S9PXo0SqsC/CK7B/Q1/3FycnUXWXuzCIZhri5ej/6507zk7v00nMoz06oNHL7j3XxuBY1GCwrsmZd3u3mJ+euAbj2srGq5hezsrGvX0wEAIpFbXNzoN5YslTfJJZJam5RnOYh8AY3OwGvHNChmqtFoPHZ6vVarrqktOXHmx+9/nFZZXWT9u3qHDbuT/3f2nbMAgPOXd5WU5eJUnvnONycXWifoEZlMppube2Zmxq3sTL1enzBu8pW0Cykpe2Vy2a3szJ+2/KdPZL8e3YMAAFZWNcvNy1mzdvnxE4caGxvy7+YeOrxPJHITidxsUqrl37WziKFXG9RyLYtn+1OJHA5/2Zu//305ecPWWTW1j3zFoRPHrXzqwcewwXMUioYjp77ffWClf9eIV+MTf//jE5zuTpBVK1zdO8lVpenT5v66c+v1G+l7fz8xfPioWknN/j+Sf/zpew8Pz6i+L8yf96b5Y1ZWNZs0cUZjY8OPm9f9Z/2XDAZj6Mtx6/+TZJP9srXZwK6erCt7ZHILIOPz7RV5Nf1inXpE8ogupLU/f6vy7ubkH+6o90Md3lQydpG3s8jCf/I2L/F178016Tvb+Yt2wjCDf2gnfCgCZm0Og9zELDbHJK1WOHtY/idplNas+9HyPF1sppNKY/laradbwJsLtj1rtRZ8/EVsW6sMBj2VauEH9BWHLpi1sa3vqi1u8A9h0xgwzoHRiVkbjw8aLzq4obytIPKcBO8tSba4SqtVMxiWn/SjUGx8BNBWDQAArU7DoFuY1IFGa3PgazQYax9KJ75hj+nLkZasxcJZSO8Z7VRXK+e5WRgtUak0gau3pe+zK9vWIKuUDplom6v4SIc8ZQcUM1qklDQpG/E6uQ0VaaXMiWsMiUbvGiLA00dCk98T/3OrSqfu5AcujVVNqvqmYdPciS6EpNo1JF/4TUBhWmkn7helVU1ArZiyzIfoQsirXUHEMGzJuu6y8npZdZszfjquhtIGBqYat5j48S6ZdeAkxZRlPkKhoTijTFbTSV5O1lAuu3ehxD+IFj+79a3IiJ117GTKS2OEIdG8S4frJA+UJiqd78Z1xHlIVDKNvFZp1GhE3vSRa7oy2Z3q5gYH1eGzeq7ujLELvaoeqQuzmx7crmZyaEYjRmVQqXQGjTZeAAABMUlEQVQqhUYFuN3F+DwwDNPrDEatXq81aFU6JpvSI8IpsI8bmhkRHs94etnTj+Xpxxo4TlRfpZVKdAqZXiHVG/RGgx7GIDJYGIVK4fI5HD5V1IXh5Ox4vXin97zXOQSeDIEn6leQ54WuqDoSrjPNoSc9EHgy2xq8oSA6EjaXIinXEF3FM9JpjWUFCmeR5f0nCqIj8ejK0mkcdVKe+iqNlVs8URAdiU8gB8PArfMOOVnZ+d8rXnq1zUnz4XpfM9Ielw7V6nSmbr34Qm8HmFVfIdNLazV/76t6faUvt+3zFSiIDin3qjQvXaZWGjS4zQxjE25dmI01Wv9w7ktjRNZfZ4mC6MBMJqBVQx1Ek9HE4rbrwhUKIgIFdLCCQAEFEYECCiICBRREBAooiAgUUBARKPw/UQ7qSwMCYJAAAAAASUVORK5CYII=",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(react_graph.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora vamos a probar el agente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Suma 3 y 4.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add (5363731c-6429-4c9e-904a-fa786ef18602)\n",
            " Call ID: 5363731c-6429-4c9e-904a-fa786ef18602\n",
            "  Args:\n",
            "    b: 4.0\n",
            "    a: 3.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "7\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "messages = [HumanMessage(content=\"Suma 3 y 4.\")]\n",
        "messages = react_graph.invoke({\"messages\": messages})\n",
        "\n",
        "for m in messages['messages']:  \n",
        "    # Imprime el mensaje de una forma m치s legible\n",
        "    # pretty_print() es una funci칩n que se utiliza para imprimir el mensaje de una forma m치s legible.\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos validar que est치 usando las tools solicitando diferntes operaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Multiplica eso por si mismo.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Por favor, proporciona un n칰mero para multiplicar por s칤 mismo.\n"
          ]
        }
      ],
      "source": [
        "messages = [HumanMessage(content=\"Multiplica eso por si mismo.\")]\n",
        "messages = react_graph.invoke({\"messages\": messages})\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**춰No conservamos la memoria del 7 de nuestro chat inicial!**\n",
        "\n",
        "Esto ocurre porque el estado es transitorio y solo dura durante la ejecuci칩n de un 칰nico grafo. Por lo tanto, esto limita nuestra capacidad para mantener conversaciones de varios turnos o con interrupciones. Podemos resolver este problema utilizando persistencia.\n",
        "\n",
        "LangGraph permite usar un `checkpointer` para guardar autom치ticamente el estado del grafo despu칠s de cada paso.\n",
        "\n",
        "Esta capa de persistencia incorporada nos da memoria, permitiendo que LangGraph retome desde la 칰ltima actualizaci칩n de estado.\n",
        "\n",
        "Uno de los checkpointers m치s sencillos de usar es `MemorySaver`, que es un almac칠n clave-valor en memoria para el estado del grafo. Solo necesitamos compilar el grafo con un checkpointer, 춰y as칤 nuestro grafo tendr치 memoria!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver  # Importamos MemorySaver para guardar el estado en memoria\n",
        "memory = MemorySaver()  # Creamos una instancia de MemorySaver (almac칠n en memoria para el estado del grafo)\n",
        "react_graph_memory = builder.compile(checkpointer=memory)  # Compilamos el grafo usando el checkpointer para habilitar la persistencia (memoria)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Representaci칩n del Flujo en LangGraph\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    A[Estado inicial: {state: \"I\"}] --> N1[游댮 Nodo 1]\n",
        "    N1 --> N2[游댯 Nodo 2]\n",
        "    N2 --> B[Estado final: {state: \"I heart langgraph\"}]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### 游댳 Conceptos Clave\n",
        "\n",
        "| Componente     | Descripci칩n                                                                 |\n",
        "|----------------|-----------------------------------------------------------------------------|\n",
        "| **Grafo**      | Flujo de control entre nodos y aristas.                                    |\n",
        "| **Super-pasos**| Cada nodo secuencial representa un super-paso. Nodos paralelos comparten el mismo super-paso. |\n",
        "| **Checkpoints**| En cada super-paso se guarda el estado y metadatos relevantes.             |\n",
        "| **Thread (Hilo)**  | Colecci칩n de checkpoints que representan una ejecuci칩n del grafo.       |\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplo de Checkpoints para diferentes aplicaciones\n",
        "\n",
        "#### 游댮 Checkpoint del Nodo 1\n",
        "```json\n",
        "{\n",
        "  \"state\": \"I heart\",\n",
        "  \"next\": \"nodo 2\",\n",
        "  \"id\": \"...\",\n",
        "  \"otros\": \"...\"\n",
        "}\n",
        "```\n",
        "\n",
        "#### 游댯 Checkpoint del Nodo 2\n",
        "```json\n",
        "{\n",
        "  \"state\": \"I heart langgraph\",\n",
        "  \"next\": \"end\",\n",
        "  \"id\": \"...\",\n",
        "  \"otros\": \"...\"\n",
        "}\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "###  Hilo (Thread)\n",
        "\n",
        "Una **colecci칩n de checkpoints** ordenados que representan una ejecuci칩n completa del grafo. Sirve como historial y permite la recuperaci칩n o an치lisis de cada paso.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora vamos a definir un Thread y hacer de nuevo otros llamados usando la memoria"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Suma 3 y 4.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add (eae4c54d-fa09-44ab-b3cc-35f45f807c64)\n",
            " Call ID: eae4c54d-fa09-44ab-b3cc-35f45f807c64\n",
            "  Args:\n",
            "    b: 4.0\n",
            "    a: 3.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "7\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "# Definir la configuraci칩n para el hilo espec칤fico donde se almacenar치 el historial de la conversaci칩n.\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Crear el mensaje de entrada que el usuario env칤a al agente.\n",
        "messages = [HumanMessage(content=\"Suma 3 y 4.\")]\n",
        "\n",
        "# Ejecutar el grafo de razonamiento con memoria, pasando los mensajes y la configuraci칩n del hilo.\n",
        "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
        "\n",
        "# Recorrer todos los mensajes resultantes y mostrarlos de forma legible.\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si utilizamos el mismo `thread_id`, el agente puede continuar desde el 칰ltimo estado guardado en el historial (`checkpoint`) de la conversaci칩n.\n",
        "\n",
        "Es decir, toda la conversaci칩n previa (por ejemplo, la suma de 3 y 4) queda registrada en el hilo identificado por ese `thread_id`.\n",
        "\n",
        "Cuando enviamos un nuevo mensaje del usuario, como `Multiplica eso por 2.`, este mensaje se a침ade al historial de la conversaci칩n en ese mismo hilo.\n",
        "\n",
        "De esta manera, el modelo tiene acceso al contexto completo: sabe que \"eso\" se refiere al resultado anterior (\"La suma de 3 y 4 es 7\"), y puede realizar la nueva operaci칩n correctamente (multiplicar 7 por 2).\n",
        "\n",
        "As칤, la memoria del hilo permite que el agente entienda referencias a mensajes previos y mantenga coherencia en la conversaci칩n."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Suma 3 y 4.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  add (eae4c54d-fa09-44ab-b3cc-35f45f807c64)\n",
            " Call ID: eae4c54d-fa09-44ab-b3cc-35f45f807c64\n",
            "  Args:\n",
            "    b: 4.0\n",
            "    a: 3.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: add\n",
            "\n",
            "7\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "7\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Multiplica eso por 2.\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  multiply (3b8ce371-5c10-4713-a883-77a673cf74e6)\n",
            " Call ID: 3b8ce371-5c10-4713-a883-77a673cf74e6\n",
            "  Args:\n",
            "    b: 2.0\n",
            "    a: 7.0\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: multiply\n",
            "\n",
            "14\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "messages = [HumanMessage(content=\"Multiplica eso por 2.\")]\n",
        "messages = react_graph_memory.invoke({\"messages\": messages}, config)\n",
        "for m in messages['messages']:\n",
        "    m.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Studio\n",
        "\n",
        "### AVISO IMPORTANTE\n",
        "\n",
        "LangGraph Studio ha sido actualizado para que puedas ejecutarlo localmente en tu propia m치quina y abrirlo directamente en tu navegador web. Esta es ahora la forma recomendada de utilizar Studio, en lugar de la aplicaci칩n de escritorio\n",
        "\n",
        "쯈u칠 significa esto?\n",
        "\n",
        "- Ya no necesitas instalar una aplicaci칩n de escritorio separada.\n",
        "- Puedes iniciar el servidor de desarrollo localmente, lo que te permite trabajar de manera m치s flexible y r치pida.\n",
        "- El entorno de Studio se abrir치 en tu navegador, facilitando la interacci칩n y el desarrollo.\n",
        "\n",
        "쮺칩mo lo hago?\n",
        "\n",
        "1. Abre una terminal y navega a la carpeta donde haya desarrolado el agente, ejemplo `Ejemplos\\Agente expuesto en un API `.\n",
        "2. Ejecuta el siguiente comando para iniciar el servidor de desarrollo local de LangGraph Studio:\n",
        "\n",
        "  ```\n",
        "  langgraph dev\n",
        "  ```\n",
        "\n",
        "3. Una vez iniciado, abre tu navegador y accede a la direcci칩n local que se mostrar치 en la terminal (por lo general, `http://localhost:8000` o similar).\n",
        "\n",
        "Para m치s detalles y documentaci칩n sobre c칩mo utilizar el servidor de desarrollo local y las nuevas funcionalidades de Studio, consulta la documentaci칩n oficial de LangGraph Studio.\n",
        "\n",
        "De esta manera, podr치s experimentar y desarrollar tus flujos de trabajo de manera m치s eficiente y c칩moda directamente desde tu navegador."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agente expuesto como servicio de API\n",
        "\n",
        "Para finalizar este tutorial b치scio, recomedamos leer `Ejemplos\\Agente expuesto en un API ` donde se expone una forma de como desplegar un agente con memoria y diferetentes tools por medio de un API. Remitase al `Ejemplos\\Agente expuesto en un API\\README.md` y siga las instrucciones para ejecutar el agente."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "kernel-lg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
