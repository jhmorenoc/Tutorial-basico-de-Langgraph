{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agentes en LangGraph con Gemini\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Caso 5 Orquestados\n",
        "\n",
        "<img src=\"https://langchain-ai.github.io/langgraph/tutorials/workflows/img/worker.png\" alt=\"gate\" width=\"600\"/>\n",
        "\n",
        "Con el patrón orquestador-trabajador, un orquestador descompone una tarea y delega cada sub-tarea a trabajadores. Como se menciona en el blog de Anthropic sobre la construcción de agentes efectivos:\n",
        "\n",
        "En el flujo de trabajo orquestador-trabajadores, un LLM central descompone dinámicamente las tareas, las delega a LLMs trabajadores y sintetiza sus resultados.\n",
        "\n",
        "Cuándo usar este flujo de trabajo: Este flujo es adecuado para tareas complejas donde no se pueden predecir las sub-tareas necesarias (por ejemplo, en programación, la cantidad de archivos que deben cambiarse y la naturaleza de cada cambio probablemente dependa de la tarea). Aunque es topográficamente similar a la paralelización, la diferencia clave es su flexibilidad: las sub-tareas no están predefinidas, sino que son determinadas por el orquestador según la entrada específica.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated, List\n",
        "import operator\n",
        "from langgraph.types import Send\n",
        "from pydantic import BaseModel, Field\n",
        "from typing_extensions import TypedDict\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from IPython.display import Image, display\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Declaración y llamado de la key del modelo LLM\n",
        "# use esta función para definir la key del modelo LLM si tuvo problemas con el archivo .env.json o create_env.py\n",
        "def _set_env(var: str):\n",
        "   if not os.environ.get(var):\n",
        "       os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"GOOGLE_API_KEY\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Primero definimos el esquema para salida estructurada a usar en la planificación:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Section(BaseModel):\n",
        "    name: str = Field(\n",
        "        description=\"Nombre para esta sección del informe.\",\n",
        "    )\n",
        "    description: str = Field(\n",
        "        description=\"Breve descripción de los temas y conceptos principales que se cubrirán en esta sección.\",\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Definición del modelo Sections para estructurar la salida del planificador. Incluye una lista de secciones, cada una representando una parte del informe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Sections(BaseModel):\n",
        "    sections: List[Section] = Field(\n",
        "        description=\"Secciones del informe.\",  # Descripción \n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora Aumentamos el LLM con un esquema para salida estructurada usando el modelo `Sections`. Esto permite que el modelo genere una respuesta estructurada según el esquema definido en `Sections`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "planner = llm.with_structured_output(Sections)  # El planificador ahora devolverá secciones del informe en formato estructurado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creando Workers en LangGraph\n",
        "\n",
        "Debido a que los flujos de trabajo de orquestador-trabajador son comunes, LangGraph tiene la API Send para soportar esto. Permite crear dinámicamente nodos worker y enviar a cada uno una entrada específica. Cada worker tiene su propio estado, y todas las salidas de los workers se escriben en una clave de estado compartida que es accesible para el grafo del orquestador. Esto le da al orquestador acceso a todas las salidas de los workers y le permite sintetizarlas en una salida final. Como puedes ver abajo, iteramos sobre una lista de secciones y enviamos cada una a un nodo worker. Consulta la documentación adicional aquí y aquí."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estado del grafo\n",
        "class State(TypedDict):\n",
        "    topic: str  # Tema del informe\n",
        "    sections: list[Section]  # Lista de secciones del informe\n",
        "    completed_sections: Annotated[\n",
        "        list, operator.add\n",
        "    ]  # Todas las workers escriben en esta clave en paralelo\n",
        "    final_report: str  # Informe final\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la siguiente celda se define la estructura y lógica del orquestador en el flujo de trabajo de generación de informes. Primero, se declara el estado que manejará cada worker (`WorkerState`), el cual contiene la sección específica que debe procesar cada worker y una lista acumulativa de secciones completadas, permitiendo la ejecución paralela y la agregación de resultados.\n",
        "\n",
        "Luego, se implementa la función `orchestrator`, que actúa como el nodo orquestador del grafo. Esta función toma el estado global, utiliza el planificador (basado en un modelo de lenguaje) para generar un plan estructurado del informe a partir del tema proporcionado, y devuelve las secciones generadas en un formato estructurado. \n",
        "\n",
        "El orquestador es responsable de descomponer el problema principal (elaborar el informe) en sub-tareas (secciones), que luego serán distribuidas a los workers para su desarrollo individual.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Estado del worker (Worker state)\n",
        "class WorkerState(TypedDict):\n",
        "    section: Section  # Sección que el worker debe procesar\n",
        "    completed_sections: Annotated[list, operator.add]  # Lista acumulada de secciones completadas por los workers\n",
        "\n",
        "# Nodos (Nodes)\n",
        "def orchestrator(state: State):\n",
        "    \"\"\"Orquestador que genera un plan para el informe\"\"\"\n",
        "\n",
        "    # Generar las secciones del informe usando el planificador\n",
        "    report_sections = planner.invoke(\n",
        "        [\n",
        "            SystemMessage(content=\"Genera un plan para el informe.\"),  # Instrucción al modelo para crear el plan\n",
        "            HumanMessage(content=f\"Aquí está el tema del informe: {state['topic']}\"),  # Proporciona el tema al modelo\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Devuelve las secciones generadas en formato estructurado\n",
        "    return {\"sections\": report_sections.sections}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SE define la funcion `llm_call` que representa el nodo worker encargado de redactar una sección individual del informe. Recibe el estado específico del worker, que contiene la sección a desarrollar y la lista acumulada de secciones completadas. Utiliza un modelo de lenguaje (LLM) para generar el contenido de la sección, proporcionando como contexto el nombre y la descripción de la sección. La instrucción al modelo especifica que debe escribir la sección en formato markdown, sin incluir preámbulos. El resultado generado por el modelo se agrega a la lista de secciones completadas, que será utilizada posteriormente para sintetizar el informe completo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def llm_call(state: WorkerState):\n",
        "    \"\"\"Worker que escribe una sección del informe\"\"\"\n",
        "\n",
        "    # Generar la sección del informe utilizando el modelo de lenguaje\n",
        "    section = llm.invoke(\n",
        "        [\n",
        "            SystemMessage(\n",
        "                content=\"Escribe una sección del informe siguiendo el nombre y la descripción proporcionados. No incluyas ningún preámbulo para cada sección. Utiliza formato markdown.\"\n",
        "            ),\n",
        "            HumanMessage(\n",
        "                content=f\"Aquí está el nombre de la sección: {state['section'].name} y la descripción: {state['section'].description}\"\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # Escribir la sección generada en la lista de secciones completadas\n",
        "    return {\"completed_sections\": [section.content]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la siguiente celda define dos funciones clave para el flujo de trabajo del orquestador:\n",
        "\n",
        "1. `synthesizer(state: State)`: Esta función toma el estado actual, que contiene una lista de secciones del informe ya completadas (`completed_sections`). Su propósito es sintetizar el informe final uniendo todas las secciones en una sola cadena de texto, separadas por delimitadores (`\\n\\n---\\n\\n`). El resultado se devuelve en un diccionario bajo la clave `\"final_report\"`, listo para ser utilizado o presentado como el informe completo.\n",
        "\n",
        "2. `assign_workers(state: State)`: Esta función es utilizada como función condicional de borde en el grafo de estados. Recibe el estado actual, accede a la lista de secciones planificadas (`state[\"sections\"]`) y para cada sección crea una instrucción para enviar el trabajo al nodo `\"llm_call\"`, pasando la sección correspondiente. Esto permite que cada sección del informe sea redactada en paralelo por un worker independiente.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def synthesizer(state: State):\n",
        "    \"\"\"Sintetiza el informe completo a partir de las secciones\"\"\"\n",
        "\n",
        "    # Lista de secciones completadas\n",
        "    completed_sections = state[\"completed_sections\"]\n",
        "\n",
        "    # Formatea las secciones completadas como una sola cadena, separadas por delimitadores, para usarlas como contexto en las secciones finales\n",
        "    completed_report_sections = \"\\n\\n---\\n\\n\".join(completed_sections)\n",
        "\n",
        "    # Devuelve el informe final como un solo string\n",
        "    return {\"final_report\": completed_report_sections}\n",
        "\n",
        "\n",
        "# Función condicional de borde para crear workers llm_call que escriben cada sección del informe\n",
        "def assign_workers(state: State):\n",
        "    \"\"\"Asigna un worker a cada sección en el plan\"\"\"\n",
        "\n",
        "    # Inicia la escritura de secciones en paralelo usando la API Send()\n",
        "    return [Send(\"llm_call\", {\"section\": s}) for s in state[\"sections\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Construimos el workflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "orchestrator_worker_builder = StateGraph(State)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora definimos los nodos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x22c1e458410>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orchestrator_worker_builder.add_node(\"orchestrator\", orchestrator)\n",
        "orchestrator_worker_builder.add_node(\"llm_call\", llm_call)\n",
        "orchestrator_worker_builder.add_node(\"synthesizer\", synthesizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y las aristas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x22c1e458410>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "orchestrator_worker_builder.add_edge(START, \"orchestrator\")\n",
        "orchestrator_worker_builder.add_conditional_edges(\n",
        "    \"orchestrator\", assign_workers, [\"llm_call\"]\n",
        ")\n",
        "orchestrator_worker_builder.add_edge(\"llm_call\", \"synthesizer\")\n",
        "orchestrator_worker_builder.add_edge(\"synthesizer\", END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ya podemos compilar el grafo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "orchestrator_worker = orchestrator_worker_builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lo visualizamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(orchestrator_worker.get_graph().draw_mermaid_png()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Y finalmente hacemos una prueba de invocación del grafo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "# Introducción a los LLM\n",
              "\n",
              "Los Modelos Lingüísticos Grandes (LLM) son un tipo de modelo de inteligencia artificial (IA) entrenado en grandes cantidades de datos de texto. Pueden realizar una variedad de tareas relacionadas con el lenguaje, como:\n",
              "\n",
              "* **Generación de texto:** Los LLM pueden generar texto similar al humano en una variedad de estilos, como poemas, código, guiones, piezas musicales, correo electrónico, cartas, etc. También pueden traducir entre idiomas y resumir texto.\n",
              "* **Comprensión del lenguaje:** Los LLM pueden comprender el texto escrito, incluida la identificación del tema principal, encontrar información específica y responder preguntas.\n",
              "* **Diálogo:** Los LLM pueden conversar con los humanos de forma natural, respondiendo preguntas y haciendo preguntas relevantes.\n",
              "\n",
              "Los LLM se basan típicamente en arquitecturas de aprendizaje profundo, como las redes neuronales transformadoras. Estas arquitecturas permiten que los LLM aprendan los patrones y las estructuras del lenguaje, lo que les permite generar y comprender texto similar al humano. El tamaño de los LLM puede variar desde unos pocos millones hasta cientos de miles de millones de parámetros. En general, los modelos más grandes tienden a funcionar mejor, pero también requieren más recursos computacionales para entrenar y usar.\n",
              "\n",
              "Los LLM tienen el potencial de revolucionar la forma en que interactuamos con las computadoras. Pueden facilitar tareas como escribir, investigar y comunicarse con otros. Sin embargo, también es importante tener en cuenta los riesgos potenciales asociados con los LLM, como la posibilidad de que se utilicen para generar información errónea o propaganda.\n",
              "\n",
              "---\n",
              "\n",
              "## Leyes de escalado para los LLM\n",
              "\n",
              "El rendimiento de los grandes modelos lingüísticos (LLM) está intrínsecamente ligado al tamaño del modelo, el tamaño del conjunto de datos y la potencia de cálculo utilizada durante el entrenamiento. La relación entre estos factores a menudo se rige por las leyes de escalado, que proporcionan información sobre cómo mejora el rendimiento al escalar los recursos.\n",
              "\n",
              "Las leyes de escalado normalmente muestran una relación de ley de potencia entre el rendimiento del modelo (medido por métricas como la pérdida o la precisión) y los recursos (tamaño del modelo, tamaño del conjunto de datos o cálculo). En otras palabras, aumentar los recursos normalmente conduce a una mejora del rendimiento, pero con rendimientos decrecientes.\n",
              "\n",
              "**Tamaño del modelo:** Aumentar el número de parámetros en un LLM generalmente conduce a un mejor rendimiento en diversas tareas. Sin embargo, la relación entre el tamaño del modelo y el rendimiento no es lineal. Después de cierto punto, aumentar aún más el tamaño del modelo produce mejoras de rendimiento marginalmente más pequeñas. Se han propuesto varias leyes de escalado para capturar esta relación, a menudo indicando una ley de potencia con un exponente decreciente.\n",
              "\n",
              "**Tamaño del conjunto de datos:** De manera similar al tamaño del modelo, escalar el tamaño del conjunto de datos de entrenamiento también mejora el rendimiento. Un conjunto de datos más grande expone al modelo a una mayor diversidad de lenguaje y patrones, lo que lleva a una mejor generalización. Sin embargo, las ganancias de rendimiento disminuyen a medida que aumenta el tamaño del conjunto de datos, lo que sugiere que existe un límite en la cantidad de datos que un modelo puede utilizar de manera efectiva.\n",
              "\n",
              "**Potencia de cálculo:** La potencia de cálculo juega un papel crucial en el entrenamiento de los LLM. Una mayor potencia de cálculo permite entrenar modelos más grandes en conjuntos de datos más grandes durante más tiempo. La relación entre la potencia de cálculo y el rendimiento también sigue una ley de escalado, pero la tasa de mejora puede variar según el modelo y la arquitectura de entrenamiento específicos.\n",
              "\n",
              "Comprender estas leyes de escalado es esencial para el desarrollo eficiente de LLM. Al cuantificar la relación entre los recursos y el rendimiento, los investigadores pueden tomar decisiones informadas sobre cómo asignar los recursos de manera óptima para lograr las mejoras de rendimiento deseadas. Además, las leyes de escalado pueden ayudar a predecir el rendimiento de los modelos futuros y guiar la investigación en el desarrollo de arquitecturas de modelos más eficientes.\n",
              "\n",
              "---\n",
              "\n",
              "### Implicaciones de las leyes de escalado\n",
              "\n",
              "Las leyes de escalado han surgido como un principio rector crucial en el desarrollo de modelos de lenguaje grande (LLM). Describen la relación predecible entre el tamaño del modelo (número de parámetros), los datos de entrenamiento y el rendimiento computacional. En esencia, las leyes de escalado sugieren que aumentar el tamaño del modelo y los datos de entrenamiento, junto con una potencia de cálculo proporcional, conduce a una mejora continua del rendimiento del modelo. Esta observación ha tenido profundas implicaciones para la investigación y desarrollo de LLM, dando forma a las estrategias de investigación y generando expectativas sobre el futuro de estos modelos.\n",
              "\n",
              "Una de las implicaciones más significativas de las leyes de escalado es el impulso hacia modelos aún más grandes. A medida que la investigación inicial demostró una fuerte correlación entre el tamaño del modelo y el rendimiento, hubo una tendencia a entrenar modelos cada vez más grandes. Esta tendencia ha dado lugar a una serie de LLM con miles de millones, e incluso billones, de parámetros, lo que ha logrado resultados notables en diversas tareas de PNL. Sin embargo, el simple escalado también trae consigo desafíos, incluido el creciente costo computacional y la huella ambiental del entrenamiento de estos modelos masivos.\n",
              "\n",
              "Además, las leyes de escalado han resaltado la importancia de los datos de entrenamiento. A medida que aumenta el tamaño de los modelos, también aumenta su apetito por los datos. Esto ha llevado a los investigadores a explorar nuevas formas de adquirir y curar conjuntos de datos masivos, lo que incluye técnicas novedosas para el filtrado y la limpieza de datos. La calidad de los datos de entrenamiento se ha vuelto cada vez más crítica, ya que los modelos más grandes son susceptibles de aprender y amplificar los sesgos presentes en los datos, lo que genera preocupaciones éticas y prácticas.\n",
              "\n",
              "Otra implicación de las leyes de escalado es la necesidad de arquitecturas de modelos más eficientes. A medida que el escalado ingenuo se vuelve prohibitivamente costoso, los investigadores están explorando activamente nuevas arquitecturas y técnicas de entrenamiento que pueden lograr un rendimiento similar con menores requisitos computacionales. Esto incluye explorar arquitecturas de modelos dispersos, técnicas de aprendizaje por transferencia y otras innovaciones destinadas a mejorar la eficiencia del entrenamiento y la inferencia.\n",
              "\n",
              "Por último, las leyes de escalado han suscitado importantes cuestiones sobre los límites del escalado. Si bien las tendencias iniciales sugirieron una mejora continua con el tamaño, no está claro si estas leyes se mantendrán indefinidamente. Hay preguntas abiertas sobre si hay un punto de rendimientos decrecientes o si surgirán limitaciones fundamentales. La investigación futura deberá explorar estos límites y determinar si existen límites inherentes a la escalabilidad de los LLM.\n",
              "\n",
              "En resumen, las leyes de escalado han tenido una profunda influencia en la trayectoria de la investigación y desarrollo de los LLM. Han impulsado la tendencia hacia modelos más grandes, han destacado la importancia de los datos, han motivado la investigación en arquitecturas de modelos eficientes y han planteado preguntas fundamentales sobre los límites del escalado. A medida que el campo continúa evolucionando, comprender y abordar las implicaciones de las leyes de escalado seguirá siendo crucial para el desarrollo de LLM más capaces y sostenibles.\n",
              "\n",
              "---\n",
              "\n",
              "## Conclusión\n",
              "\n",
              "Este informe ha examinado [tema del informe]. Nuestros hallazgos indican que [hallazgo clave 1] y que [hallazgo clave 2]. Además, hemos descubierto que [hallazgo clave 3].\n",
              "\n",
              "Estos hallazgos tienen varias implicaciones. En primer lugar, sugieren que [implicación 1]. En segundo lugar, apuntan hacia la necesidad de [implicación 2]. Por último, plantean interrogantes sobre [implicación 3].\n",
              "\n",
              "Se justifican futuras investigaciones para abordar varias cuestiones sin resolver. En primer lugar, sería útil investigar [dirección futura de la investigación 1]. Además, sería informativo explorar [dirección futura de la investigación 2]. Por último, un estudio sobre [dirección futura de la investigación 3] podría arrojar luz sobre [cuestión sin resolver]."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Invocación\n",
        "state = orchestrator_worker.invoke({\"topic\": \"Crea un informe sobre las leyes de escalado de los LLM\"})\n",
        "\n",
        "from IPython.display import Markdown\n",
        "Markdown(state[\"final_report\"])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "kernel-lg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
